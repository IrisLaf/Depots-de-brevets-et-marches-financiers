{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f434098e",
   "metadata": {},
   "source": [
    "# Importation des donn√©es\n",
    "[To Do : continuer de d√©crire origine et format des donn√©es]\n",
    "\n",
    "Les donn√©es sont localis√©es dans des fichiers XML, chaque fichier correspondant √† une demande de brevets. Ces fichiers sont directement t√©l√©chargeables depuis le serveur FTP de l'INPI, accessible via FileZilla.\n",
    "\n",
    "Pour rendre notre projet reproductible au maximum, bien que les donn√©es ne puissent pas √™tre directement t√©l√©charg√©es par un utilisateur non autoris√© par l'INPI, nous avons stock√© les fichiers .zip tels que nous les avons initialement t√©l√©charg√©s dans le bucket diffusion de l'un de nous. \n",
    "\n",
    "Concernant leur format, ces fichiers compress√©s contiennent chacun les informations sur toutes les demandes de brevets d√©pos√©s aupr√®s de l'INPI chaque semaine. Il y a donc 52 dossiers par ann√©e, un pour chaque semaine. Dans ces dossiers, se trouvent des informations dont nous n'avons pas besoin (ex: des sch√©mas d'invention). Nous n'utiliserons que les donn√©es pr√©sentes dans des fichiers XML, chacun de ces fichiers contenant de nombreuses informations sur une demande de brevet d√©pos√©e dans la semaine concern√©e.\n",
    "\n",
    "Le code suivant se charge de d√©compresser ces fichiers, d'identifier les fichiers XML au sein de leurs arborescences et d'en extraire toutes les informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c14c022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.importation import process_all_years_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c60bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion au bucket S3 (MinIO)\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "\n",
    "ROOT_S3_PATH = \"mvallat/diffusion/projet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d13e3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Traitement du dossier 2021...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_01.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_02.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_03.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_04.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_05.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_06.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_07.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_08.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_09.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_10.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_11.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_12.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_13.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_14.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_15.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_16.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_17.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_18.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_19.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_20.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_21.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_22.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_23.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_24.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_25.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_26.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_27.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_28.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_29.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_30.zip...\n",
      "  üóúÔ∏è Traitement de FR_FRNEWST36_2021_31.zip...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# NB : ce code tourne 2-3min\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m data_brevets = \u001b[43mprocess_all_years_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mROOT_S3_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m data_brevets.head(\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/Projet-Python/scripts/importation.py:20\u001b[39m, in \u001b[36mprocess_all_years_s3\u001b[39m\u001b[34m(fs, root_s3_path)\u001b[39m\n\u001b[32m     18\u001b[39m year_name = year_path.rstrip(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m).split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m]\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìÇ Traitement du dossier \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m df_year = \u001b[43mprocess_year_folder_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_year.empty:\n\u001b[32m     22\u001b[39m     df_year[\u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m] = year_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/Projet-Python/scripts/importation.py:41\u001b[39m, in \u001b[36mprocess_year_folder_s3\u001b[39m\u001b[34m(fs, year_path)\u001b[39m\n\u001b[32m     39\u001b[39m zip_name = zip_s3_path.split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m]\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  üóúÔ∏è Traitement de \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m df_zip = \u001b[43mextract_from_zip_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_s3_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_zip.empty:\n\u001b[32m     43\u001b[39m     all_brevets.append(df_zip)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/Projet-Python/scripts/importation.py:68\u001b[39m, in \u001b[36mextract_from_zip_s3\u001b[39m\u001b[34m(fs, zip_s3_path)\u001b[39m\n\u001b[32m     66\u001b[39m xml_content = io.BytesIO(xml_file.read())\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     df_brevet = \u001b[43mextract_brevet_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     all_brevets.append(df_brevet)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/Projet-Python/scripts/importation.py:315\u001b[39m, in \u001b[36mextract_brevet_info\u001b[39m\u001b[34m(xml_file_path)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/frame.py:855\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    853\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    854\u001b[39m         columns = ensure_index(columns)\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m     arrays, columns, index = \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[32m    858\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    863\u001b[39m     mgr = arrays_to_mgr(\n\u001b[32m    864\u001b[39m         arrays,\n\u001b[32m    865\u001b[39m         columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    868\u001b[39m         typ=manager,\n\u001b[32m    869\u001b[39m     )\n\u001b[32m    870\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/internals/construction.py:520\u001b[39m, in \u001b[36mnested_data_to_arrays\u001b[39m\u001b[34m(data, columns, index, dtype)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[32m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    518\u001b[39m     columns = ensure_index(data[\u001b[32m0\u001b[39m]._fields)\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m arrays, columns = \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m columns = ensure_index(columns)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/internals/construction.py:845\u001b[39m, in \u001b[36mto_arrays\u001b[39m\u001b[34m(data, columns, dtype)\u001b[39m\n\u001b[32m    842\u001b[39m     data = [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m    843\u001b[39m     arr = _list_to_arrays(data)\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m content, columns = \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/internals/construction.py:945\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    942\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[32m0\u001b[39m].dtype == np.object_:\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     contents = \u001b[43mconvert_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m contents, columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/internals/construction.py:1071\u001b[39m, in \u001b[36mconvert_object_array\u001b[39m\u001b[34m(content, dtype, dtype_backend, coerce_float)\u001b[39m\n\u001b[32m   1067\u001b[39m             arr = maybe_cast_to_datetime(arr, dtype)\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m arrays = [\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m content]\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/internals/construction.py:1046\u001b[39m, in \u001b[36mconvert_object_array.<locals>.convert\u001b[39m\u001b[34m(arr)\u001b[39m\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arr.dtype == np.dtype(\u001b[33m\"\u001b[39m\u001b[33mO\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1044\u001b[39m     \u001b[38;5;66;03m# i.e. maybe_convert_objects didn't convert\u001b[39;00m\n\u001b[32m   1045\u001b[39m     convert_to_nullable_dtype = dtype_backend != \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1046\u001b[39m     arr = \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1047\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_nullable_dtype \u001b[38;5;129;01mand\u001b[39;00m arr.dtype == np.dtype(\u001b[33m\"\u001b[39m\u001b[33mO\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1048\u001b[39m         new_dtype = StringDtype()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/dtypes/cast.py:1200\u001b[39m, in \u001b[36mmaybe_infer_to_datetimelike\u001b[39m\u001b[34m(value, convert_to_nullable_dtype)\u001b[39m\n\u001b[32m   1195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m   1197\u001b[39m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[32m   1198\u001b[39m \u001b[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[32m   1199\u001b[39m \u001b[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   1201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[32m   1203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[32m   1204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_non_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_if_all_nat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mM8[ns]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# NB : ce code tourne 2-3min\n",
    "data_brevets = process_all_years_s3(fs, ROOT_S3_PATH)\n",
    "data_brevets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8311c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation bucket S3\n",
    "MY_BUCKET = \"mvallat/diffusion\"\n",
    "FILE_PATH_OUT_S3 = f\"{MY_BUCKET}/projet/data_brevets.parquet\"\n",
    "\n",
    "with fs.open(FILE_PATH_OUT_S3, 'wb') as file_out:\n",
    "    data_brevets.to_parquet(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc1d9e",
   "metadata": {},
   "source": [
    "Notre base de donn√©es est maintenant stock√©e dans une bucket diffusion sur le ssp cloud, ce qui nous permet de ne pas avoir √† repartir des fichiers compress√©s initiaux. \n",
    "\n",
    "**Pour importer directement les donn√©es sans passer par les √©tapes pr√©c√©dentes, on pourra utiliser le code suivant :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55ceb031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_id</th>\n",
       "      <th>doc-number</th>\n",
       "      <th>kind</th>\n",
       "      <th>country</th>\n",
       "      <th>date-produced</th>\n",
       "      <th>status</th>\n",
       "      <th>publication_country</th>\n",
       "      <th>publication_doc-number</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_bopinum</th>\n",
       "      <th>...</th>\n",
       "      <th>citation_2_date</th>\n",
       "      <th>citation_3_type</th>\n",
       "      <th>citation_3_text</th>\n",
       "      <th>citation_3_country</th>\n",
       "      <th>citation_3_doc-number</th>\n",
       "      <th>citation_3_date</th>\n",
       "      <th>last-fee-payement</th>\n",
       "      <th>next-fee-payement</th>\n",
       "      <th>date-search-completed</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1800103546</td>\n",
       "      <td>3098104</td>\n",
       "      <td>A1</td>\n",
       "      <td>FR</td>\n",
       "      <td>20210108</td>\n",
       "      <td>NEW</td>\n",
       "      <td>FR</td>\n",
       "      <td>3098104</td>\n",
       "      <td>20210108</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>20210802</td>\n",
       "      <td>NA</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800103291</td>\n",
       "      <td>3098134</td>\n",
       "      <td>A1</td>\n",
       "      <td>FR</td>\n",
       "      <td>20210108</td>\n",
       "      <td>NEW</td>\n",
       "      <td>FR</td>\n",
       "      <td>3098134</td>\n",
       "      <td>20210108</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>...</td>\n",
       "      <td>20151126</td>\n",
       "      <td>patcit</td>\n",
       "      <td>GB 2 545 190 A (QUANTUM CHEMICAL TECH  PTE\\nLT...</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB-2545190-A</td>\n",
       "      <td>20170614</td>\n",
       "      <td>20200731</td>\n",
       "      <td>20210802</td>\n",
       "      <td>20210108</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    family_id doc-number kind country date-produced status  \\\n",
       "0  1800103546    3098104   A1      FR      20210108    NEW   \n",
       "1  1800103291    3098134   A1      FR      20210108    NEW   \n",
       "\n",
       "  publication_country publication_doc-number publication_date  \\\n",
       "0                  FR                3098104         20210108   \n",
       "1                  FR                3098134         20210108   \n",
       "\n",
       "  publication_bopinum  ... citation_2_date citation_3_type  \\\n",
       "0             2021-01  ...              NA              NA   \n",
       "1             2021-01  ...        20151126          patcit   \n",
       "\n",
       "                                     citation_3_text citation_3_country  \\\n",
       "0                                                 NA                 NA   \n",
       "1  GB 2 545 190 A (QUANTUM CHEMICAL TECH  PTE\\nLT...                 GB   \n",
       "\n",
       "  citation_3_doc-number citation_3_date last-fee-payement next-fee-payement  \\\n",
       "0                    NA              NA                NA          20210802   \n",
       "1          GB-2545190-A        20170614          20200731          20210802   \n",
       "\n",
       "  date-search-completed  year  \n",
       "0                    NA  2021  \n",
       "1              20210108  2021  \n",
       "\n",
       "[2 rows x 104 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation bucket S3\n",
    "MY_BUCKET = \"mvallat/diffusion\"\n",
    "FILE_PATH_S3 = f\"{MY_BUCKET}/projet/data_brevets.parquet\"\n",
    "\n",
    "with fs.open(FILE_PATH_S3, 'rb') as file_in:\n",
    "    data_brevets = pd.read_parquet(file_in)\n",
    "\n",
    "data_brevets.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
